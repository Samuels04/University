{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2\n",
    "\n",
    "Objetivo: comprender cada técnica de *preparación de datos* y *selección de características*.\n",
    "\n",
    "\n",
    "\n",
    "**Contenido**\n",
    "1. Imports y utilidades\n",
    "2. Línea base (escalado + regresión logística)\n",
    "3. Imputación (comparación con eliminar filas perdidas)\n",
    "4. Selección tipo filtro (f\\_classif y chi2)\n",
    "5. RFECV (eliminación recursiva con validación cruzada)\n",
    "6. SelectFromModel (L1 y Random Forest)\n",
    "7. Selección de instancias\n",
    "8. (Opcional) Demostración con `Pipeline`\n",
    "9. (Opcional) Mini ejemplo de **regresión**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d05a0",
   "metadata": {},
   "source": [
    "## 1) Imports y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (569, 30) | y shape: (569,)\n",
      "Train: (426, 30) | Test: (143, 30)\n"
     ]
    }
   ],
   "source": [
    "# 1) Configuración y carga del dataset (clasificación)\n",
    "import warnings, time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Diferentes datasets de clasificación y regresión que se pueden usar\n",
    "from sklearn.datasets import load_breast_cancer, fetch_california_housing, load_diabetes\n",
    "\n",
    "# Algunas utilidades\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, chi2, RFECV, SelectFromModel\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "def standardize_train_test(Xtr, Xte):\n",
    "    sc = StandardScaler()\n",
    "    return sc.fit_transform(Xtr), sc.transform(Xte)\n",
    "\n",
    "def simulate_missingness(X, missing_rate=0.05, seed=RANDOM_STATE):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X2 = X.astype(float).copy()\n",
    "    n, d = X2.shape\n",
    "    m = int(missing_rate * n * d)\n",
    "    idx = rng.choice(n*d, m, replace=False)\n",
    "    X2[idx // d, idx % d] = np.nan\n",
    "    return X2\n",
    "\n",
    "# Cargamos un problema de clasificación: Breast Cancer (binaria)\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "print('X shape:', X.shape, '| y shape:', y.shape)\n",
    "\n",
    "# Partición train/test estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print('Train:', X_train.shape, '| Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Línea base (escalado + clasificador sencillo)\n",
    "Entrenamos sin selección ni imputación en un dataset sin valores perdidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE\n",
      "Accuracy: 0.9580  |  F1-macro: 0.9550  |  tiempo: 0.002s\n"
     ]
    }
   ],
   "source": [
    "# Escalado\n",
    "Xtr_s, Xte_s = standardize_train_test(X_train, X_test)\n",
    "\n",
    "# Clasificador ligero (rápido en aula)\n",
    "clf_base = LogisticRegression(penalty='l2', solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); clf_base.fit(Xtr_s, y_train); t_base = time.perf_counter() - t0\n",
    "yp = clf_base.predict(Xte_s)\n",
    "acc_base = accuracy_score(y_test, yp)\n",
    "f1_base = f1_score(y_test, yp, average='macro')\n",
    "\n",
    "print('BASELINE')\n",
    "print(f'Accuracy: {acc_base:.4f}  |  F1-macro: {f1_base:.4f}  |  tiempo: {t_base:.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Imputación (comparación con eliminar filas perdidas)\n",
    "Simulamos un **5%** de valores perdidos y comparamos:\n",
    "- **Eliminar filas con NaN** (train y test por separado)\n",
    "- **Imputación simple** (media)\n",
    "- **Imputación KNN** (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba021dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulamos valores perdidos\n",
    "Xtr_m = simulate_missingness(X_train, 0.05)\n",
    "Xte_m = simulate_missingness(X_test, 0.05)\n",
    "res_imput = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dae56581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Eliminar filas con NaN (cuidado: reducimos datos)\n",
    "mask_tr = ~np.isnan(Xtr_m).any(axis=1)\n",
    "mask_te = ~np.isnan(Xte_m).any(axis=1)\n",
    "Xtr_drop, ytr_drop = Xtr_m[mask_tr], y_train[mask_tr]\n",
    "Xte_drop, yte_drop = Xte_m[mask_te], y_test[mask_te]\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_drop, Xte_drop)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, ytr_drop)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Eliminar filas\",\n",
    "        Xtr_drop.shape[0],\n",
    "        Xte_drop.shape[0],\n",
    "        accuracy_score(yte_drop, yp),\n",
    "        f1_score(yte_drop, yp, average=\"macro\"),\n",
    "        t,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6ac391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) SimpleImputer (media)\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: media\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9c662c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) KNNImputer (k=5)\n",
    "imp = KNNImputer(n_neighbors=5)\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: KNN (k=5)\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4146fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Añade otro método de imputación básico\n",
    "# D) SimpleImputer (mediana)\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: mediana\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92718fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Añade otro método de imputación avanzado\n",
    "# E) SimpleImputer (mas frecuente)\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "Xtr_imp = imp.fit_transform(Xtr_m)\n",
    "Xte_imp = imp.transform(Xte_m)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr_imp, Xte_imp)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s)\n",
    "res_imput.append(\n",
    "    [\n",
    "        \"Imputación: más frecuente\",\n",
    "        Xtr_imp.shape[0],\n",
    "        Xte_imp.shape[0],\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a5d6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Usa un dataset de regresión, repite todos los métodos de imputación y muestra los resultados.\n",
    "# No olvides adaptar todas las métricas: Accuracy/F1 solo sirven para problemas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19741c",
   "metadata": {},
   "source": [
    "### ENTREGABLE: Escribe en el documento de la práctica (formato libre) un texto explicando los resultados obtenidos y decidiendo cuál es el mejor método de imputación en cada caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>tiempo_entreno_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eliminar filas</td>\n",
       "      <td>90</td>\n",
       "      <td>33</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.937970</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imputación: media</td>\n",
       "      <td>426</td>\n",
       "      <td>143</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.962378</td>\n",
       "      <td>0.002143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imputación: KNN (k=5)</td>\n",
       "      <td>426</td>\n",
       "      <td>143</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.001023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imputación: mediana</td>\n",
       "      <td>426</td>\n",
       "      <td>143</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.001065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imputación: más frecuente</td>\n",
       "      <td>426</td>\n",
       "      <td>143</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.933292</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tratamiento  n_train  n_test  Accuracy  F1-macro  \\\n",
       "0             Eliminar filas       90      33  0.939394  0.937970   \n",
       "1          Imputación: media      426     143  0.965035  0.962378   \n",
       "2      Imputación: KNN (k=5)      426     143  0.958042  0.955031   \n",
       "3        Imputación: mediana      426     143  0.958042  0.955031   \n",
       "4  Imputación: más frecuente      426     143  0.937063  0.933292   \n",
       "\n",
       "   tiempo_entreno_s  \n",
       "0          0.002151  \n",
       "1          0.002143  \n",
       "2          0.001023  \n",
       "3          0.001065  \n",
       "4          0.001062  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos resultados\n",
    "df_imput = pd.DataFrame(res_imput, columns=['Tratamiento', 'n_train', 'n_test', 'Accuracy', 'F1-macro', 'tiempo_entreno_s'])\n",
    "df_imput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Selección tipo filtro\n",
    "Comparamos *sin selección* vs **SelectKBest** con:\n",
    "- `f_classif` (general)\n",
    "- `chi2` (requiere no-negatividad, debemos aplicar `MinMaxScaler` antes de usarlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4621a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos los datos SIN NaN (X_train / X_test originales)\n",
    "imp = SimpleImputer()  # por seguridad\n",
    "Xtr = imp.fit_transform(X_train)\n",
    "Xte = imp.transform(X_test)\n",
    "Xtr_s0, Xte_s0 = standardize_train_test(Xtr, Xte)\n",
    "\n",
    "# Baseline\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_s0, y_train)\n",
    "t_base2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_s0)\n",
    "acc0 = accuracy_score(y_test, yp)\n",
    "f10 = f1_score(y_test, yp, average=\"macro\")\n",
    "\n",
    "rows = [[\"Sin selección\", Xtr.shape[1], acc0, f10, t_base2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e22bb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest f_classif (k=10)\n",
    "k = min(10, Xtr.shape[1])\n",
    "sel = SelectKBest(score_func=f_classif, k=k)\n",
    "Xtr_k = sel.fit_transform(Xtr_s0, y_train)\n",
    "Xte_k = sel.transform(Xte_s0)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_k, y_train)\n",
    "t1 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k)\n",
    "rows.append(\n",
    "    [\n",
    "        f\"SelectKBest f_classif (k={k})\",\n",
    "        k,\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t1,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest chi2 (k=10) → MinMax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "Xtr_mm = mm.fit_transform(Xtr)\n",
    "Xte_mm = mm.transform(Xte)\n",
    "sel = SelectKBest(score_func=chi2, k=k)\n",
    "Xtr_k2 = sel.fit_transform(Xtr_mm, y_train)\n",
    "Xte_k2 = sel.transform(Xte_mm)\n",
    "clf = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); clf.fit(Xtr_k2, y_train); t2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_k2)\n",
    "rows.append([f'SelectKBest chi2 (k={k})', k, accuracy_score(y_test, yp), f1_score(y_test, yp, average='macro'), t2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd89d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLIGATORIO: Prueba con diferentes valores de n_features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "k_values = [10, 20, 30, 40]\n",
    "for i in k_values:\n",
    "\tsel = SelectKBest(score_func=f_classif, k=i)\n",
    "\tXtr_k = sel.fit_transform(Xtr_s0, y_train)\n",
    "\tXte_k = sel.transform(Xte_s0)\n",
    "\tclf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "\tt0 = time.perf_counter()\n",
    "\tclf.fit(Xtr_k, y_train)\n",
    "\tt1 = time.perf_counter() - t0\n",
    "\typ = clf.predict(Xte_k)\n",
    "\trows.append(\n",
    "    \t[\n",
    "        \tf\"SelectKBest f_classif (k={i})\",\n",
    "        \tk,\n",
    "        \taccuracy_score(y_test, yp),\n",
    "        \tf1_score(y_test, yp, average=\"macro\"),\n",
    "        \tt1,\n",
    "    \t]\n",
    "\t)\n",
    "\tmm = MinMaxScaler()\n",
    "\tXtr_mm = mm.fit_transform(Xtr)\n",
    "\tXte_mm = mm.transform(Xte)\n",
    "\tsel = SelectKBest(score_func=chi2, k=i)\n",
    "\tXtr_k2 = sel.fit_transform(Xtr_mm, y_train)\n",
    "\tXte_k2 = sel.transform(Xte_mm)\n",
    "\tclf = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "\tt0 = time.perf_counter(); clf.fit(Xtr_k2, y_train); t2 = time.perf_counter() - t0\n",
    "\typ = clf.predict(Xte_k2)\n",
    "\trows.append([f'SelectKBest chi2 (k={i})', k, accuracy_score(y_test, yp), f1_score(y_test, yp, average='macro'), t2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34682e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>n_features</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>tiempo_entreno_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sin selección</td>\n",
       "      <td>30</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SelectKBest f_classif (k=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.947330</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SelectKBest chi2 (k=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>0.924451</td>\n",
       "      <td>0.000507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SelectKBest f_classif (k=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.947330</td>\n",
       "      <td>0.000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SelectKBest chi2 (k=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>0.924451</td>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SelectKBest f_classif (k=20)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.962067</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SelectKBest chi2 (k=20)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.939045</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SelectKBest f_classif (k=30)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SelectKBest chi2 (k=30)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.931121</td>\n",
       "      <td>0.000655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SelectKBest f_classif (k=40)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.000882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SelectKBest chi2 (k=40)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.931121</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tratamiento  n_features  Accuracy  F1-macro  \\\n",
       "0                  Sin selección          30  0.958042  0.955031   \n",
       "1   SelectKBest f_classif (k=10)          10  0.951049  0.947330   \n",
       "2        SelectKBest chi2 (k=10)          10  0.930070  0.924451   \n",
       "3   SelectKBest f_classif (k=10)          10  0.951049  0.947330   \n",
       "4        SelectKBest chi2 (k=10)          10  0.930070  0.924451   \n",
       "5   SelectKBest f_classif (k=20)          10  0.965035  0.962067   \n",
       "6        SelectKBest chi2 (k=20)          10  0.944056  0.939045   \n",
       "7   SelectKBest f_classif (k=30)          10  0.958042  0.955031   \n",
       "8        SelectKBest chi2 (k=30)          10  0.937063  0.931121   \n",
       "9   SelectKBest f_classif (k=40)          10  0.958042  0.955031   \n",
       "10       SelectKBest chi2 (k=40)          10  0.937063  0.931121   \n",
       "\n",
       "    tiempo_entreno_s  \n",
       "0           0.001146  \n",
       "1           0.000852  \n",
       "2           0.000507  \n",
       "3           0.000781  \n",
       "4           0.000368  \n",
       "5           0.000560  \n",
       "6           0.000460  \n",
       "7           0.000806  \n",
       "8           0.000655  \n",
       "9           0.000882  \n",
       "10          0.000635  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"Tratamiento\", \"n_features\", \"Accuracy\", \"F1-macro\", \"tiempo_entreno_s\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64bd4cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (178, 13) | y shape: (178,)\n",
      "Train: (133, 13) | Test: (45, 13)\n"
     ]
    }
   ],
   "source": [
    "# OBLIGATORIO: Usa un segundo problema de clasificación y repite todo\n",
    "# Cargamos un problema de clasificación: Breast Cancer (binaria)\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "\n",
    "data2 = load_wine()\n",
    "X2, y2 = data2.data, data2.target\n",
    "print('X shape:', X2.shape, '| y shape:', y2.shape)\n",
    "rows=[]\n",
    "# Partición train/test estratificada\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X2, y2, test_size=0.25, stratify=y2, random_state=RANDOM_STATE\n",
    ")\n",
    "print('Train:', X_train2.shape, '| Test:', X_test2.shape)\n",
    "\n",
    "imp2 = SimpleImputer()  # por seguridad\n",
    "Xtr2 = imp.fit_transform(X_train2)\n",
    "Xte2 = imp.transform(X_test2)\n",
    "Xtr_s02, Xte_s02 = standardize_train_test(Xtr2, Xte2)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "k_values = [5, 10, 15, 25]\n",
    "for j in k_values:\n",
    "\tsel = SelectKBest(score_func=f_classif, k=j)\n",
    "\tXtr_k = sel.fit_transform(Xtr_s02, y_train2)\n",
    "\tXte_k = sel.transform(Xte_s02)\n",
    "\tclf = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "\tt0 = time.perf_counter()\n",
    "\tclf.fit(Xtr_k, y_train2)\n",
    "\tt1 = time.perf_counter() - t0\n",
    "\typ = clf.predict(Xte_k)\n",
    "\trows.append(\n",
    "    \t[\n",
    "        \tf\"SelectKBest f_classif (k={j}) WINE\",\n",
    "        \tj,\n",
    "        \taccuracy_score(y_test2, yp),\n",
    "        \tf1_score(y_test2, yp, average=\"macro\"),\n",
    "        \tt1,\n",
    "    \t]\n",
    "\t)\n",
    "\tmm = MinMaxScaler()\n",
    "\tXtr_mm = mm.fit_transform(Xtr2)\n",
    "\tXte_mm = mm.transform(Xte2)\n",
    "\tsel = SelectKBest(score_func=chi2, k=j)\n",
    "\tXtr_k2 = sel.fit_transform(Xtr_mm, y_train2)\n",
    "\tXte_k2 = sel.transform(Xte_mm)\n",
    "\tclf = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "\tt0 = time.perf_counter(); clf.fit(Xtr_k2, y_train2); t2 = time.perf_counter() - t0\n",
    "\typ = clf.predict(Xte_k2)\n",
    "\trows.append([f'SelectKBest chi2 (k={j}) WINE', j, accuracy_score(y_test2, yp), f1_score(y_test2, yp, average='macro'), t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffa6b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Usa un problema de regresión, adapta lo necesario y repite todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "274b278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>n_features</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>tiempo_entreno_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SelectKBest f_classif (k=5) WINE</td>\n",
       "      <td>5</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.956654</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SelectKBest chi2 (k=5) WINE</td>\n",
       "      <td>5</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.979497</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SelectKBest f_classif (k=10) WINE</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SelectKBest chi2 (k=10) WINE</td>\n",
       "      <td>10</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.979497</td>\n",
       "      <td>0.000315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SelectKBest f_classif (k=15) WINE</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SelectKBest chi2 (k=15) WINE</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SelectKBest f_classif (k=25) WINE</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SelectKBest chi2 (k=25) WINE</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Tratamiento  n_features  Accuracy  F1-macro  \\\n",
       "0   SelectKBest f_classif (k=5) WINE           5  0.955556  0.956654   \n",
       "1        SelectKBest chi2 (k=5) WINE           5  0.977778  0.979497   \n",
       "2  SelectKBest f_classif (k=10) WINE          10  1.000000  1.000000   \n",
       "3       SelectKBest chi2 (k=10) WINE          10  0.977778  0.979497   \n",
       "4  SelectKBest f_classif (k=15) WINE          15  1.000000  1.000000   \n",
       "5       SelectKBest chi2 (k=15) WINE          15  1.000000  1.000000   \n",
       "6  SelectKBest f_classif (k=25) WINE          25  1.000000  1.000000   \n",
       "7       SelectKBest chi2 (k=25) WINE          25  1.000000  1.000000   \n",
       "\n",
       "   tiempo_entreno_s  \n",
       "0          0.000458  \n",
       "1          0.000313  \n",
       "2          0.000350  \n",
       "3          0.000315  \n",
       "4          0.000375  \n",
       "5          0.000335  \n",
       "6          0.000376  \n",
       "7          0.000334  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"Tratamiento\", \"n_features\", \"Accuracy\", \"F1-macro\", \"tiempo_entreno_s\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f284a72",
   "metadata": {},
   "source": [
    "### ENTREGABLE: Escribe en el documento de la práctica (formato libre) un texto explicando los resultados obtenidos y decidiendo cuál es el mejor número de características en cada caso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) RFECV\n",
    "Usamos **RFECV** para encontrar automáticamente cuántas características dejar. Después reentrenamos una RL con esas características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV\n",
      "n_features seleccionadas: 6\n",
      "Accuracy: 0.9441  |  F1-macro: 0.9400  |  tiempo_total: 1.093s\n"
     ]
    }
   ],
   "source": [
    "imp = SimpleImputer(); Xtr = imp.fit_transform(X_train); Xte = imp.transform(X_test)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr, Xte)\n",
    "\n",
    "est = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "rfecv = RFECV(estimator=est, step=2, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "t0 = time.perf_counter(); rfecv.fit(Xtr_s, y_train); t_sel = time.perf_counter() - t0\n",
    "nsel = int(getattr(rfecv, 'n_features_', Xtr.shape[1]))\n",
    "\n",
    "Xtr_sel = rfecv.transform(Xtr_s); Xte_sel = rfecv.transform(Xte_s)\n",
    "final = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter(); final.fit(Xtr_sel, y_train); t_fit = time.perf_counter() - t0\n",
    "yp = final.predict(Xte_sel)\n",
    "\n",
    "print('RFECV')\n",
    "print('n_features seleccionadas:', nsel)\n",
    "print(f'Accuracy: {accuracy_score(y_test, yp):.4f}  |  F1-macro: {f1_score(y_test, yp, average=\"macro\"):.4f}  |  tiempo_total: {t_sel + t_fit:.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf08ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest con f_regression\n",
      "n_features:  6\n"
     ]
    }
   ],
   "source": [
    "# OBLIGATORIO: Compara RFECV con filtro en las mismas condiciones (mismo dataset, misma imputación/escalado, mismo número de características) y explica cuál es mejor\n",
    "imp = SimpleImputer(); Xtr = imp.fit_transform(X_train); Xte = imp.transform(X_test)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr, Xte)\n",
    "\n",
    "est = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "filt = SelectKBest(score_func=f_regression, k=6)\n",
    "t0 = time.perf_counter();filt.fit(Xtr_s, y_train); t_sel = time.perf_counter() - t0\n",
    "nsel = 0\n",
    "features = filt.get_support()\n",
    "for i in features:\n",
    "\tif i:\n",
    "\t\tnsel += 1\n",
    "print('SelectKBest con f_regression')\n",
    "print('n_features: ', nsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de869d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No escogen las mismas columnas\n",
      "['x7' 'x20' 'x21' 'x22' 'x23' 'x27'] ['x0' 'x2' 'x7' 'x20' 'x22' 'x27']\n"
     ]
    }
   ],
   "source": [
    "# OBLIGATORIO: Eligen RFECV y filtro las mismas variables?\n",
    "maks_rfe = rfecv.get_support()\n",
    "mask_filter = filt.get_support()\n",
    "\n",
    "rfe = rfecv.get_feature_names_out()\n",
    "fil = filt.get_feature_names_out()\n",
    "\n",
    "for i in range(6):\n",
    "\tif rfe[i] != fil[i]:\n",
    "\t\tprint(\"No escogen las mismas columnas\")\n",
    "\t\tprint(rfe, fil)\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22393712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Repite todo para un problema de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a199ed",
   "metadata": {},
   "source": [
    "### ENTREGABLE: Escribe en el documento de la práctica (formato libre) un texto explicando los resultados obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) SelectFromModel\n",
    "Primero seleccionamos características y luego reentrenamos para comparar solo el efecto de la selección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5198e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer()\n",
    "Xtr = imp.fit_transform(X_train)\n",
    "Xte = imp.transform(X_test)\n",
    "Xtr_s, Xte_s = standardize_train_test(Xtr, Xte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6820ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "# L1 como selector\n",
    "sel1 = SelectFromModel(\n",
    "    LogisticRegression(penalty=\"l1\", solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    ")\n",
    "t0 = time.perf_counter()\n",
    "sel1.fit(Xtr_s, y_train)\n",
    "t_sel1 = time.perf_counter() - t0\n",
    "Xtr_sel = sel1.transform(Xtr_s)\n",
    "Xte_sel = sel1.transform(Xte_s)\n",
    "clf = LogisticRegression(penalty=\"l2\", solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_sel, y_train)\n",
    "t_fit1 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_sel)\n",
    "rows.append(\n",
    "    [\n",
    "        \"SFM(L1 LR) + LR L2\",\n",
    "        int(sel1.get_support().sum()),\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t_sel1 + t_fit1,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5957bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest como selector\n",
    "sel2 = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    ")\n",
    "t0 = time.perf_counter()\n",
    "sel2.fit(Xtr_s, y_train)\n",
    "t_sel2 = time.perf_counter() - t0\n",
    "Xtr_sel = sel2.transform(Xtr_s)\n",
    "Xte_sel = sel2.transform(Xte_s)\n",
    "clf = LogisticRegression(penalty=\"l2\", solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_sel, y_train)\n",
    "t_fit2 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_sel)\n",
    "rows.append(\n",
    "    [\n",
    "        \"SFM(RandomForest) + LR L2\",\n",
    "        int(sel2.get_support().sum()),\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t_sel2 + t_fit2,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d63ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>n_features</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>tiempo_total_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SFM(L1 LR) + LR L2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.004190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SFM(RandomForest) + LR L2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.947330</td>\n",
       "      <td>0.093798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SFM(AdaBoost) + LR L2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.954670</td>\n",
       "      <td>0.206191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tratamiento  n_features  Accuracy  F1-macro  tiempo_total_s\n",
       "0         SFM(L1 LR) + LR L2          14  0.958042  0.955031        0.004190\n",
       "1  SFM(RandomForest) + LR L2           9  0.951049  0.947330        0.093798\n",
       "2      SFM(AdaBoost) + LR L2          13  0.958042  0.954670        0.206191"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OBLIGATORIO: Compara los tres métodos de selección de características en las mismas condiciones \n",
    "# (usando el mismo dataset, misma imputación/escalado, mismo número de características) y explica cuál es mejor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "sel3 = SelectFromModel(\n",
    "\tAdaBoostClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
    ")\n",
    "t0 = time.perf_counter()\n",
    "sel3.fit(Xtr_s, y_train)\n",
    "t_sel3 = time.perf_counter() - t0\n",
    "Xtr_sel = sel3.transform(Xtr_s)\n",
    "Xte_sel = sel3.transform(Xte_s)\n",
    "clf = LogisticRegression(penalty=\"l2\", solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(Xtr_sel, y_train)\n",
    "t_fit3 = time.perf_counter() - t0\n",
    "yp = clf.predict(Xte_sel)\n",
    "rows.append(\n",
    "    [\n",
    "        \"SFM(AdaBoost) + LR L2\",\n",
    "        int(sel3.get_support().sum()),\n",
    "        accuracy_score(y_test, yp),\n",
    "        f1_score(y_test, yp, average=\"macro\"),\n",
    "        t_sel3 + t_fit3,\n",
    "    ]\n",
    ")\n",
    "pd.DataFrame(rows, columns=['Tratamiento', 'n_features', 'Accuracy', 'F1-macro', 'tiempo_total_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No escogen las mismas columnas\n",
      "['x6' 'x7' 'x9' 'x10' 'x14' 'x15' 'x18' 'x20' 'x21' 'x23' 'x24' 'x26'\n",
      " 'x27' 'x28']\n",
      "['x2' 'x3' 'x6' 'x7' 'x20' 'x22' 'x23' 'x26' 'x27']\n",
      "['x7' 'x8' 'x10' 'x12' 'x15' 'x19' 'x21' 'x22' 'x23' 'x24' 'x26' 'x27'\n",
      " 'x29']\n"
     ]
    }
   ],
   "source": [
    "# OBLIGATORIO: Elige este método las mismas variables que los anteriores? \n",
    "sel_1 = sel1.get_feature_names_out()\n",
    "sel_2 = sel2.get_feature_names_out()\n",
    "sel_3 = sel3.get_feature_names_out()\n",
    "\n",
    "for i in range(6):\n",
    "\tif sel_1[i] != sel_2[i] and sel_1[i] != sel_3[i] and sel_2[i] != sel_3[i]:\n",
    "\t\tprint(\"No escogen las mismas columnas\")\n",
    "\t\tprint(sel_1)\n",
    "\t\tprint(sel_2)\n",
    "\t\tprint(sel_3)\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Repite todo para un problema de regresión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389908f5",
   "metadata": {},
   "source": [
    "### ENTREGABLE: Escribe en el documento de la práctica (formato libre) un texto explicando los resultados obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Selección de instancias\n",
    "Reducimos deliberadamente el tamaño del conjunto de entrenamiento y comparamos con entrenar con todo el train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485bc3f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **CNN** (Condensed Nearest Neighbour): condensa el train manteniendo representantes.\n",
    "- **ENN** (Edited Nearest Neighbours): elimina ejemplos conflictivos.\n",
    "\n",
    "> Requiere imbalanced-learn: pip install imbalanced-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33337d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import CondensedNearestNeighbour, EditedNearestNeighbours\n",
    "\n",
    "# Preprocesado (imputación + escalado con train)\n",
    "imp = SimpleImputer()\n",
    "Xtr = imp.fit_transform(X_train)\n",
    "Xte = imp.transform(X_test)\n",
    "sc = StandardScaler()\n",
    "Xtr_s = sc.fit_transform(Xtr)\n",
    "Xte_s = sc.transform(Xte)\n",
    "\n",
    "rows = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Todo el train\n",
    "clf_full = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf_full.fit(Xtr_s, y_train)\n",
    "t_full = time.perf_counter() - t0\n",
    "yp_full = clf_full.predict(Xte_s)\n",
    "acc_full = accuracy_score(y_test, yp_full)\n",
    "f1_full = f1_score(y_test, yp_full, average=\"macro\")\n",
    "rows.append([\"Todo el train\", Xtr_s.shape[0], acc_full, f1_full, t_full])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64678af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) CNN (condensado)\n",
    "cnn = CondensedNearestNeighbour(random_state=RANDOM_STATE)\n",
    "Xtr_cnn, ytr_cnn = cnn.fit_resample(Xtr_s, y_train)\n",
    "clf_cnn = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf_cnn.fit(Xtr_cnn, ytr_cnn)\n",
    "t_cnn = time.perf_counter() - t0\n",
    "yp_cnn = clf_cnn.predict(Xte_s)\n",
    "rows.append(\n",
    "    [\n",
    "        \"CNN (condensado)\",\n",
    "        Xtr_cnn.shape[0],\n",
    "        accuracy_score(y_test, yp_cnn),\n",
    "        f1_score(y_test, yp_cnn, average=\"macro\"),\n",
    "        t_cnn,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) ENN (edición)\n",
    "enn = EditedNearestNeighbours()\n",
    "Xtr_enn, ytr_enn = enn.fit_resample(Xtr_s, y_train)\n",
    "clf_enn = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf_enn.fit(Xtr_enn, ytr_enn)\n",
    "t_enn = time.perf_counter() - t0\n",
    "yp_enn = clf_enn.predict(Xte_s)\n",
    "rows.append(\n",
    "    [\n",
    "        \"ENN (edición)\",\n",
    "        Xtr_enn.shape[0],\n",
    "        accuracy_score(y_test, yp_enn),\n",
    "        f1_score(y_test, yp_enn, average=\"macro\"),\n",
    "        t_enn,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>n_instancias_train</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>tiempo_entreno_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Todo el train</td>\n",
       "      <td>426</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.003766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN (condensado)</td>\n",
       "      <td>201</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.948116</td>\n",
       "      <td>0.000794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENN (edición)</td>\n",
       "      <td>408</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.948116</td>\n",
       "      <td>0.002671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tratamiento  n_instancias_train  Accuracy  F1-macro  tiempo_entreno_s\n",
       "0     Todo el train                 426  0.958042  0.955031          0.003766\n",
       "1  CNN (condensado)                 201  0.951049  0.948116          0.000794\n",
       "2     ENN (edición)                 408  0.951049  0.948116          0.002671"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"Tratamiento\",\n",
    "        \"n_instancias_train\",\n",
    "        \"Accuracy\",\n",
    "        \"F1-macro\",\n",
    "        \"tiempo_entreno_s\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97755fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (581012, 54) | y shape: (581012,)\n",
      "Train: (435759, 54) | Test: (145253, 54)\n"
     ]
    }
   ],
   "source": [
    "# OBLIGATORIO: Usa un nuevo dataset de clasificación y repítelo todo\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, EditedNearestNeighbours\n",
    "from sklearn.datasets import fetch_covtype\n",
    "\n",
    "data = fetch_covtype()\n",
    "X, y = data.data, data.target\n",
    "print('X shape:', X.shape, '| y shape:', y.shape)\n",
    "\n",
    "# Partición train/test estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print('Train:', X_train.shape, '| Test:', X_test.shape)\n",
    "\n",
    "# Preprocesado (imputación + escalado con train)\n",
    "imp = SimpleImputer()\n",
    "Xtr = imp.fit_transform(X_train)\n",
    "Xte = imp.transform(X_test)\n",
    "sc = StandardScaler()\n",
    "Xtr_s = sc.fit_transform(Xtr)\n",
    "Xte_s = sc.transform(Xte)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# A) Todo el train\n",
    "clf_full = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf_full.fit(Xtr_s, y_train)\n",
    "t_full = time.perf_counter() - t0\n",
    "yp_full = clf_full.predict(Xte_s)\n",
    "acc_full = accuracy_score(y_test, yp_full)\n",
    "f1_full = f1_score(y_test, yp_full, average=\"macro\")\n",
    "rows.append([\"Todo el train\", Xtr_s.shape[0], acc_full, f1_full, t_full])\n",
    "# B) CNN (condensado)\n",
    "cnn = CondensedNearestNeighbour(random_state=RANDOM_STATE)\n",
    "Xtr_cnn, ytr_cnn = cnn.fit_resample(Xtr_s, y_train)\n",
    "clf_cnn = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf_cnn.fit(Xtr_cnn, ytr_cnn)\n",
    "t_cnn = time.perf_counter() - t0\n",
    "yp_cnn = clf_cnn.predict(Xte_s)\n",
    "rows.append(\n",
    "    [\n",
    "        \"CNN (condensado)\",\n",
    "        Xtr_cnn.shape[0],\n",
    "        accuracy_score(y_test, yp_cnn),\n",
    "        f1_score(y_test, yp_cnn, average=\"macro\"),\n",
    "        t_cnn,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# C) ENN (edición)\n",
    "enn = EditedNearestNeighbours()\n",
    "Xtr_enn, ytr_enn = enn.fit_resample(Xtr_s, y_train)\n",
    "clf_enn = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "t0 = time.perf_counter()\n",
    "clf_enn.fit(Xtr_enn, ytr_enn)\n",
    "t_enn = time.perf_counter() - t0\n",
    "yp_enn = clf_enn.predict(Xte_s)\n",
    "rows.append(\n",
    "    [\n",
    "        \"ENN (edición)\",\n",
    "        Xtr_enn.shape[0],\n",
    "        accuracy_score(y_test, yp_enn),\n",
    "        f1_score(y_test, yp_enn, average=\"macro\"),\n",
    "        t_enn,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0721c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>n_instancias_train</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>tiempo_entreno_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Todo el train</td>\n",
       "      <td>435759</td>\n",
       "      <td>0.715249</td>\n",
       "      <td>0.478830</td>\n",
       "      <td>98.227430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN (condensado)</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.207631</td>\n",
       "      <td>0.187563</td>\n",
       "      <td>0.203019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENN (edición)</td>\n",
       "      <td>364485</td>\n",
       "      <td>0.715730</td>\n",
       "      <td>0.487959</td>\n",
       "      <td>25.255179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tratamiento  n_instancias_train  Accuracy  F1-macro  tiempo_entreno_s\n",
       "0     Todo el train              435759  0.715249  0.478830         98.227430\n",
       "1  CNN (condensado)                4274  0.207631  0.187563          0.203019\n",
       "2     ENN (edición)              364485  0.715730  0.487959         25.255179"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"Tratamiento\",\n",
    "        \"n_instancias_train\",\n",
    "        \"Accuracy\",\n",
    "        \"F1-macro\",\n",
    "        \"tiempo_entreno_s\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c9d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Usa un dataset de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5e663",
   "metadata": {},
   "source": [
    "### ENTREGABLE: Escribe en el documento de la práctica (formato libre) un texto explicando los resultados obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demostración de Pipeline (sin entregables)\n",
    "Esto no es necesario para entender los métodos; simplemente muestra cómo encadenar pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"imp\", SimpleImputer()),\n",
    "        (\"sc\", StandardScaler()),\n",
    "        (\n",
    "            \"sel\",\n",
    "            SelectFromModel(\n",
    "                LogisticRegression(\n",
    "                    penalty=\"l1\", solver=\"liblinear\", random_state=RANDOM_STATE\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"clf\",\n",
    "            LogisticRegression(\n",
    "                penalty=\"l2\", solver=\"liblinear\", random_state=RANDOM_STATE\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "t0 = time.perf_counter()\n",
    "pipe.fit(X_train, y_train)\n",
    "t = time.perf_counter() - t0\n",
    "yp = pipe.predict(X_test)\n",
    "print(\n",
    "    f\"Pipeline → Accuracy: {accuracy_score(y_test, yp):.4f} | F1-macro: {f1_score(y_test, yp, average='macro'):.4f} | tiempo: {t:.3f}s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb4e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
